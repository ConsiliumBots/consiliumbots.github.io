{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true;\n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "}\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#--------------------------- Libraries ---------------------------//\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import scipy, random, copy, h5py, pandas, math, csv, sys, os, pickle, re, json, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from sklearn import preprocessing\n",
    "from numpy.random import RandomState\n",
    "from scipy import ndimage\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "from datetime import datetime\n",
    "import os.path as osp\n",
    "\n",
    "#--------------------------- Users, directories and some routines ---------------------------//\n",
    "path = os.getcwd()\n",
    "repo_dir = \"/Users/germanriveros/Documents/GitHub/QueVasaEstudiar\"\n",
    "data_dir = repo_dir + \"/python/data\"\n",
    "\n",
    "sub_routines = os.path.join(repo_dir,'python', 'sub_routines')\n",
    "sys.path.append(sub_routines)\n",
    "from neural_predictor import neural_predictor\n",
    "from Import_MenuParameters import Import_MenuParameters\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "intervention = '11/05/2019' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/germanriveros/Documents/GitHub/QueVasaEstudiarpython/Options_Outcomes_08_10_2018.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-643e216237af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#1.1. IMPORT DATA ABOUT OPTIONS:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0moutcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadOutcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mHEOptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marange_outcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-643e216237af>\u001b[0m in \u001b[0;36mloadOutcomes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadOutcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'python/Options_Outcomes_08_10_2018.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/germanriveros/Documents/GitHub/QueVasaEstudiarpython/Options_Outcomes_08_10_2018.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# #--------------------------- Functions ---------------------------//\n",
    "def loadOutcomes():\n",
    "    outcomes = {}\n",
    "    with open(repo_dir + '/python/Options_Outcomes_08_10_2018.csv', encoding = 'utf-8' ) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            outcomes[int(row['Option_ID'])] = row\n",
    "    return outcomes\n",
    "\n",
    "def arange_outcomes(outcomes):\n",
    "    HEOptions = {\n",
    "    'MajorName'       : np.array([outcomes[x]['Option_Major_Name'] for x in outcomes.keys()]),\n",
    "    'OptionID'        : np.array([x for x in outcomes.keys()]).astype(int),\n",
    "    'InstCode'        : np.array([outcomes[x]['Option_Institution_Code'] for x in outcomes.keys()]).astype(int) -1,\n",
    "    'Cutoff'          : np.array([outcomes[x]['LowerBoundScore'] for x in outcomes.keys()]).astype(float),\n",
    "    'NoSearch'        : np.array([outcomes[x]['NoSearch'] for x in outcomes.keys()]).astype(int),\n",
    "    'LevelCode'       : np.array([outcomes[x]['Option_Level_Code'] for x in outcomes.keys()]).astype(int) -1,\n",
    "    'AreaCode'        : np.array([outcomes[x]['Option_Area_Code'] for x in outcomes.keys()]).astype(int) -1,\n",
    "    'LocationCode'    : np.array([outcomes[x]['Option_Location_Code'] for x in outcomes.keys()]).astype(int) -1,\n",
    "    'MajorCode'       : np.array([outcomes[x]['Option_Major_Code'] for x in outcomes.keys()]).astype(int) -1,\n",
    "    'AverageEarning'  : np.array([outcomes[x]['Outcome_IncomeAve'] if outcomes[x]['Outcome_IncomeAve'] != \"\" else \"-999\" for x in outcomes.keys()]).astype(float)\n",
    "    }\n",
    "\n",
    "    HEOptions['AreaID']     = np.array(list(set(HEOptions['AreaCode'])))\n",
    "    HEOptions['InstID']     = np.array(list(set(HEOptions['InstCode'])))      #We have to change this part\n",
    "    HEOptions['LevelID']    = np.array(list(set(HEOptions['LevelCode'])))\n",
    "    HEOptions['LocationID'] = np.array(list(set(HEOptions['LocationCode'])))\n",
    "    HEOptions['MajorID']    = np.array(list(set(HEOptions['MajorCode'])))\n",
    "\n",
    "    #Fixes:\n",
    "    aux_InstID = np.array(range(HEOptions['InstID'].shape[0]))\n",
    "\n",
    "    for y in HEOptions:\n",
    "        HEOptions[y] = HEOptions[y][:,np.newaxis]\n",
    "\n",
    "    for i in range(HEOptions['InstID'].shape[0]):\n",
    "        HEOptions['InstCode'][HEOptions['InstCode'] == HEOptions['InstID'][i,0]] = aux_InstID[i]\n",
    "\n",
    "    HEOptions['RelevantInst']  = aux_InstID[:,np.newaxis]\n",
    "    HEOptions['normW']         = 10000000\n",
    "    HEOptions['AverageEarning'][HEOptions['AverageEarning'] == -999] = np.nan\n",
    "\n",
    "    return HEOptions\n",
    "\n",
    "# #--------------------------- Data Arrange ---------------------------//\n",
    "\n",
    "#1.1. IMPORT DATA ABOUT OPTIONS:\n",
    "outcomes = loadOutcomes()\n",
    "HEOptions = arange_outcomes(outcomes)\n",
    "\n",
    "# 1.3. IMPORT DATA ABOUT ALL INTERACTIONS:\n",
    "allinteractions = pd.read_csv(data_dir +'/chatbotprogress_data/allinteractions.csv', error_bad_lines=False)\n",
    "allinteractions[\"year\"] = allinteractions.timestamp.str[0:4].astype(int)\n",
    "allinteractions[\"month\"] = allinteractions.timestamp.str[5:7].astype(int)\n",
    "allinteractions[\"day\"] = allinteractions.timestamp.str[8:10].astype(int)\n",
    "allinteractions[\"second\"] = allinteractions.timestamp.str[17:19].astype(int)\n",
    "allinteractions[\"minute\"] = allinteractions.timestamp.str[14:16].astype(int)\n",
    "allinteractions[\"hour\"] = allinteractions.timestamp.str[11:13].astype(int) - 7\n",
    "allinteractions[\"hour\"][allinteractions[\"hour\"]==-7] = 17\n",
    "allinteractions[\"hour\"][allinteractions[\"hour\"]==-6] = 18\n",
    "allinteractions[\"hour\"][allinteractions[\"hour\"]==-5] = 19\n",
    "allinteractions[\"hour\"][allinteractions[\"hour\"]==-4] = 20\n",
    "allinteractions[\"hour\"][allinteractions[\"hour\"]==-3] = 21\n",
    "allinteractions[\"hour\"][allinteractions[\"hour\"]==-2] = 22\n",
    "allinteractions[\"hour\"][allinteractions[\"hour\"]==-1] = 23\n",
    "\n",
    "allinteractions = allinteractions[(allinteractions.year == int(intervention.split(\"/\")[2])) & (allinteractions.month == int(intervention.split(\"/\")[1])) & (allinteractions.day >= int(intervention.split(\"/\")[0])) ]\n",
    "allinteractions = allinteractions[(allinteractions.user != \"992\") & (allinteractions.user != \"YBOF9JBM8DE9ME6RE1K4\") & (allinteractions.user != \"EMF393CY0PX7ESW0BNQ\")]\n",
    "allinteractions = allinteractions.sort_values(['month','day'])\n",
    "allinteractions['Cummulative'] = np.cumsum(np.ones((allinteractions.shape[0],1))).astype(int)\n",
    "allinteractions['Interacted'] = 1\n",
    "allinteractions['times'] = list(map(lambda x: x[0:10] + \" \" + x[11:19], allinteractions['timestamp']))\n",
    "allinteractions['times'] = list(map(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'), allinteractions['times']))\n",
    "allinteractions['hours'] = list(map(lambda x: x[0:10] + \" \" + x[11:13], allinteractions['timestamp']))\n",
    "allinteractions['hours'] = list(map(lambda x: datetime.strptime(x, '%Y-%m-%d %H'), allinteractions['hours']))\n",
    "allinteractions['days'] = list(map(lambda x: x[0:10] , allinteractions['timestamp']))\n",
    "allinteractions['days'] = list(map(lambda x: datetime.strptime(x, '%Y-%m-%d'), allinteractions['days']))\n",
    "\n",
    "#1.3. IMPORT DATA ABOUT WAGE DEVIATIONS:\n",
    "wageDeviation   = pd.read_csv(data_dir +'/chatbotprogress_data/wage_deviation.csv'.format(100)).drop(columns = ['Unnamed: 0']).rename(columns= {'studentID': 'user'})\n",
    "wageDeviation[\"year\"] = wageDeviation.time.str[0:4].astype(int)\n",
    "wageDeviation[\"month\"] = wageDeviation.time.str[5:7].astype(int)\n",
    "wageDeviation[\"day\"] = wageDeviation.time.str[8:10].astype(int)\n",
    "# Filter the intervention\n",
    "wageDeviation = wageDeviation[(wageDeviation.year == int(intervention.split(\"/\")[2])) & (wageDeviation.month >= int(intervention.split(\"/\")[1])) & (wageDeviation.day >= int(intervention.split(\"/\")[0])) ]\n",
    "\n",
    "wageDeviation['hours'] = list(map(lambda x: x[0:10] + \" \" + x[11:13], wageDeviation['time']))\n",
    "wageDeviation['hours'] = list(map(lambda x: datetime.strptime(x, '%Y-%m-%d %H'), wageDeviation['hours']))\n",
    "wageDeviation['times'] = list(map(lambda x: x[0:10] + \" \" + x[11:19], wageDeviation['time']))\n",
    "wageDeviation['times'] = list(map(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'), wageDeviation['times']))\n",
    "wageDeviation['days'] = list(map(lambda x: x[0:10] , wageDeviation['time']))\n",
    "wageDeviation['days'] = list(map(lambda x: datetime.strptime(x, '%Y-%m-%d'), wageDeviation['days']))\n",
    "wageDeviation['interaction'] = 1\n",
    "wageDeviation['absWageDeviation'] = list(map(lambda x: abs(x), wageDeviation['wagedeviation']))\n",
    "\n",
    "# Number of Menus by user\n",
    "wageDeviation = wageDeviation.sort_values(by = ['user', 'times'])\n",
    "wageDeviation['numberMenu'] = -999\n",
    "wageDeviation['numberMenu'] = wageDeviation.groupby('user')['times'].rank(ascending=True).astype(int)\n",
    "\n",
    "# No vectorized code\n",
    "# for i in range(1,wageDeviation.shape[0]):\n",
    "#     if wageDeviation['user'].iloc[i] == wageDeviation['user'].iloc[i-1]:\n",
    "#         j += 1\n",
    "#         wageDeviation['numberMenu'].iloc[i] = j\n",
    "#     else:\n",
    "#         j = 1\n",
    "#         wageDeviation['numberMenu'].iloc[i] = j\n",
    "\n",
    "wageDeviation['numberMenu'][wageDeviation['numberMenu'] == 8] = 8\n",
    "wageDeviation['numberMenu'][wageDeviation['numberMenu'] == 9] = 8\n",
    "wageDeviation['numberMenu'][wageDeviation['numberMenu']>=10] = 9\n",
    "wageDeviation['N_total']=1\n",
    "\n",
    "#=================Data for performance of the Structural and ML model====================\n",
    "parameters = {}\n",
    "path_pickle = repo_dir + \"/python/data/NN_Parameters\"\n",
    "with open(path_pickle + '/parameters_nn.pickle', 'rb') as handle:\n",
    "    parameters['NN'] = pickle.load(handle)\n",
    "\n",
    "studentFeatures = pd.read_csv(repo_dir + '/Students_Features_Spring2019.csv'.format(100))\n",
    "interactionsBot = pd.read_csv(data_dir + '/chatbotprogress_data/interactions_bot.csv'.format(100))\n",
    "seedAssignment  = pd.read_csv(data_dir +'/chatbotprogress_data/seeds_intervention.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "seeds = allinteractions.merge(seedAssignment,left_on = 'user', right_on = 'url_id', how = 'left')\n",
    "interactions    = seedAssignment.merge(studentFeatures, left_on = 'url_id', right_on = 'url_id', how = 'left')\n",
    "interactions    = interactions.merge(interactionsBot, left_on = 'Student_ID', right_on = 'Student_ID', how = 'inner')\n",
    "\n",
    "\n",
    "interactions[\"year\"] = interactions.timestamp.str[0:4].astype(int)\n",
    "interactions[\"month\"] = interactions.timestamp.str[5:7].astype(int)\n",
    "interactions[\"day\"] = interactions.timestamp.str[8:10].astype(int)\n",
    "interactions = interactions[(interactions.year == int(intervention.split(\"/\")[2])) & (interactions.month >= int(intervention.split(\"/\")[1])) & (interactions.day >= int(intervention.split(\"/\")[0])) ]\n",
    "\n",
    "\n",
    "#\n",
    "# n_int = interactions.shape[0]\n",
    "# n_options = HEOptions['MajorName'].shape[0]\n",
    "#\n",
    "# #2.2. Generate tags\n",
    "# dpto_code = list(set(studentFeatures['Student_Location_Code']))\n",
    "#\n",
    "# for x in dpto_code:\n",
    "#     interactions['dpto_'+str(x)] = (interactions['Student_Location_Code'] == x).astype(int)\n",
    "#     dpto_tag = ['dpto_'+str(x) for x in dpto_code]\n",
    "#\n",
    "# menu_tag = ['Menu1','Menu2','Menu3','Menu4']\n",
    "# tag_continuous = ['punt_rez_sede','inse_rez_sede','puntsd_rez_sede', 'insesd_rez_sede', 'edad']\n",
    "#\n",
    "# X_indexslates = np.array(interactions[menu_tag])\n",
    "# for i,j in zip(range(n_options), list(HEOptions['OptionID'][:,0])):\n",
    "#     X_indexslates[:,0][X_indexslates[:,0]==j] = i\n",
    "#     X_indexslates[:,1][X_indexslates[:,1]==j] = i\n",
    "#     X_indexslates[:,2][X_indexslates[:,2]==j] = i\n",
    "#     X_indexslates[:,3][X_indexslates[:,3]==j] = i\n",
    "#\n",
    "# X_SlateEarnigs          = HEOptions['AverageEarning'][X_indexslates].reshape(n_int,len(menu_tag))\n",
    "# X_SlateEarnigs[np.isnan(X_SlateEarnigs)] = np.nanmean(X_SlateEarnigs)\n",
    "# X_SlateEarnigs          = X_SlateEarnigs\n",
    "# X_SlateLevels           = HEOptions['LevelCode'][X_indexslates].reshape(n_int,len(menu_tag))\n",
    "# X_SlateInst             = HEOptions['InstCode'][X_indexslates].reshape(n_int,len(menu_tag))\n",
    "# X_SlateArea             = HEOptions['AreaCode'][X_indexslates].reshape(n_int,len(menu_tag))\n",
    "# X_Score                 = np.array(interactions['Student_Score']).reshape(n_int,1)\n",
    "# X_ScoreDecil            = np.array(interactions['Student_ScoreDecil']).reshape(n_int,1)\n",
    "# X_Continuous            = np.array(interactions[tag_continuous]).reshape(n_int,len(tag_continuous)).astype(int)\n",
    "# X_Gender                = np.array(interactions['Student_Gender']).reshape(n_int,1)\n",
    "# X_LocationCode          = np.array(interactions[dpto_tag]).reshape(n_int,len(dpto_tag)).astype(int)\n",
    "#\n",
    "# X                       = np.hstack((X_SlateEarnigs,X_SlateLevels,X_SlateInst,X_SlateArea,X_Gender,X_Score,X_ScoreDecil,X_LocationCode,X_Continuous))\n",
    "# Y                       = np.array(interactions['Selection']).reshape(n_int, 1) == np.concatenate((np.array(interactions[['Menu1','Menu2','Menu3','Menu4']]), np.array([-999]*n_int).reshape(n_int,1)), axis =  1)\n",
    "#\n",
    "# X                       = (X - parameters['NN']['X_mean'])/parameters['NN']['X_std']\n",
    "#\n",
    "#\n",
    "# ClickProb, _ = neural_predictor(X.T, parameters['NN'], 'NN', None, None)\n",
    "# Y_hat = ClickProb.T == ClickProb.T.max(1).reshape(n_int,1)\n",
    "#\n",
    "# #2. How does the neural network perform on the data provided by the different treatment arms??\n",
    "#\n",
    "# #2.1. Accuracy\n",
    "# Accuracy = (Y * Y_hat).sum(1).reshape(n_int,1)\n",
    "#\n",
    "# #2.2. Probability\n",
    "# Pr = (ClickProb.T * (Y * Y_hat)).sum(1).reshape(n_int,1)\n",
    "#\n",
    "# #2.3. Expected Value:\n",
    "# Pr_dist = ClickProb.T[:,:-1]/ClickProb.T[:,:-1].sum(1).reshape(n_int,1)\n",
    "# EV = (X_SlateEarnigs*Pr_dist).sum(1).reshape(n_int,1)/10**7\n",
    "#\n",
    "# #3. Compute cool graphics:\n",
    "# #3.1 Create DataFrame that allows us to create cool graphics:\n",
    "# TreatmentArm = np.array(interactions['bot']).reshape(n_int,1)\n",
    "# NeuralNet_DataFrame = pd.DataFrame(np.hstack((TreatmentArm, Accuracy, Pr, EV)), columns = ['TreatmentArm', 'Accuracy','Probability','ExpectedValue']).astype(float)\n",
    "# NeuralNet_DataFrame.TreatmentArm = NeuralNet_DataFrame.TreatmentArm.astype(int)\n",
    "\n",
    "bot_map = {\n",
    "    '11' : ('Econ',   'Unrestricted'),\n",
    "    '12' : ('Econ',   'Diverse'),\n",
    "    '13' : ('Econ',   'Targeted'),\n",
    "    '21' : ('ML',     'Unrestricted'),\n",
    "    '22' : ('ML',     'Diverse'),\n",
    "    '23' : ('ML',     'Targeted')\n",
    "    # '31' : ('Random', 'Unrestricted'),\n",
    "    # '32' : ('Random', 'Diverse'),\n",
    "    # '33' : ('Random', 'Targeted')\n",
    " }\n",
    "\n",
    "bot_types = ['11','12','13','21','22','23']\n",
    "bot_label = []\n",
    "for x in bot_types: bot_label.append(bot_map[x][0][:2] +': ' + bot_map[x][1][0])\n",
    "#\n",
    "# NeuralNet_DataFrame['TreatmentArm_Label'] = 0\n",
    "# for x in bot_types:\n",
    "#     _label  = bot_map[x][0][:2] +': ' + bot_map[x][1][0]\n",
    "#     NeuralNet_DataFrame['TreatmentArm_Label'][NeuralNet_DataFrame['TreatmentArm'] == int(x)] = _label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Daily Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gcolor = '#e6550d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cummulative progress of the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=\"times\", y=\"Cummulative\", data=allinteractions, color=gcolor)\n",
    "ax.set_xlabel('')\n",
    "for tick in ax.get_xticklabels(): tick.set_rotation(45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=\"hours\", y=\"Interacted\", data=allinteractions.groupby('hours').sum().reset_index(), color=gcolor)\n",
    "ax.set_xlabel('')\n",
    "for tick in ax.get_xticklabels(): tick.set_rotation(45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of interaction by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=\"hour\", y=\"Interacted\", data=allinteractions[allinteractions['event_name'] == 'initialQuestion'].groupby('hour').sum().reset_index(), color='maroon', label='Initial question')\n",
    "ax = sns.lineplot(x=\"hour\", y=\"Interacted\", data=allinteractions[allinteractions['event_name'] == 'askInstitution'].groupby('hour').sum().reset_index(), color='red', label='Ask institution')\n",
    "ax = sns.lineplot(x=\"hour\", y=\"Interacted\", data=allinteractions[allinteractions['event_name'] == 'askCareer'].groupby('hour').sum().reset_index(), color='green', label='Ask program')\n",
    "ax = sns.lineplot(x=\"hour\", y=\"Interacted\", data=allinteractions[allinteractions['event_name'] == 'askLevel'].groupby('hour').sum().reset_index(), color='salmon', label='Ask level')\n",
    "ax = sns.lineplot(x=\"hour\", y=\"Interacted\", data=allinteractions[allinteractions['event_name'] == 'OPTIONS'].groupby('hour').sum().reset_index(), color='gray', label='Brain options')\n",
    "ax = sns.lineplot(x=\"hour\", y=\"Interacted\", data=allinteractions[allinteractions['event_name'] == 'OPTIONS_SELECTION'].groupby('hour').sum().reset_index(), color='orange', label='Select Option')\n",
    "ax = sns.lineplot(x=\"hour\", y=\"Interacted\", data=allinteractions[allinteractions['event_name'] == 'web_click'].groupby('hour').sum().reset_index(), color='orange', label='Web Click')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wage deviation from true value by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = list(set(wageDeviation['days']))\n",
    "last_date.sort()\n",
    "last_date = str(last_date[-1])\n",
    "fig, ax1 = plt.subplots()\n",
    "ax = sns.lineplot(x=\"days\", y=\"interaction\", data=wageDeviation[wageDeviation['days']<last_date].groupby(['days']).sum().reset_index(), color='blue')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Number of interactions', color='tab:blue')\n",
    "ax.tick_params(axis='y', labelcolor='tab:blue')\n",
    "ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2 = sns.lineplot(x=\"days\", y=\"absWageDeviation\", data=wageDeviation[wageDeviation['days']<last_date], color='red')\n",
    "ax2.set_ylabel('Wage Differential', color='tab:red')  # we already handled the x-label with ax1\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "for tick in ax.get_xticklabels(): tick.set_rotation(45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wage deviation from true value by number of menu interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.lineplot(x=\"numberMenu\", y=\"absWageDeviation\", data=wageDeviation[wageDeviation['days']<last_date], color=gcolor)\n",
    "ax.set_xlabel('Number of Menu')\n",
    "ax.set_ylabel('Percentage deviation from true value', color='tab:blue')\n",
    "ax.tick_params(axis='y', labelcolor='tab:blue')\n",
    "ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2 = sns.lineplot(x=\"numberMenu\", y=\"N_total\", data=wageDeviation[wageDeviation['days']<last_date].groupby(['numberMenu']).sum().reset_index(), color='gray')\n",
    "ax2.set_ylabel('Number of observations', color='tab:red')  # we already handled the x-label with ax1\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "labels = [int(x) for x in ax.get_xticks().tolist()]\n",
    "labels[-2]='>9'\n",
    "ax.set_xticklabels(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of students assigned to each treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds['count'] = 1\n",
    "ax = sns.barplot(x=\"bot\", y=\"count\", data=seeds.groupby(['bot']).sum().reset_index(), capsize=.2)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Number of treatments assigned')\n",
    "ax.set_xticklabels(bot_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of outside option clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['outsideOption'] = (interactions['Selection'] == -999)\n",
    "ax = sns.barplot(x=\"bot\", y=\"outsideOption\", data=interactions.groupby(['bot']).sum().reset_index(), capsize=.2)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Number of outside option clicks')\n",
    "ax.set_xticklabels(bot_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of outside option selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions['outsideOption'] = (interactions['Selection'] == -999)\n",
    "ax = sns.barplot(x=\"bot\", y=\"outsideOption\", data=interactions.groupby(['bot']).mean().reset_index(), capsize=.2)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Number of outside option clicks')\n",
    "ax.set_xticklabels(bot_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of menus shown by treatment arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "interactions['count'] = 1\n",
    "ax = sns.barplot(x=\"bot\", y=\"count\", data=interactions.groupby(['bot']).sum().reset_index(), capsize=.2)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Number of menus showed by treatment')\n",
    "ax.set_xticklabels(bot_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
